<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>周报-002-26Nov2023</title>
      <link href="/2023/11/26/WeeklyReport-002-26Nov2023/"/>
      <url>/2023/11/26/WeeklyReport-002-26Nov2023/</url>
      
        <content type="html"><![CDATA[<h1 id="工作周报"><a href="#工作周报" class="headerlink" title=" 工作周报 "></a><p style="text-align: center;"> 工作周报 </p></h1><p style="text-align: center;"> <b>时间: </b> 2023-11-20 ~ 2023-11-26 </p><br><h2 id="一、本周做了什么"><a href="#一、本周做了什么" class="headerlink" title="一、本周做了什么"></a>一、本周做了什么</h2><h3 id="1-pytorch扫盲"><a href="#1-pytorch扫盲" class="headerlink" title="1. pytorch扫盲"></a>1. pytorch扫盲</h3><p>学习pytorch的常用模块，并以CIFAR10编程实现一个图片分类网络以熟悉使用费pytorch进行NN搭建&amp;训练的流程<br>学习笔记：<a href="https://www.damonai.cn/2023/11/25/learn-pytorch/">https://www.damonai.cn/2023/11/25/learn-pytorch/</a><br>学习代码：github.com&#x2F;wxtcon&#x2F;learn_pytorch</p><h3 id="2-GVINS-dataset数据提取"><a href="#2-GVINS-dataset数据提取" class="headerlink" title="2. GVINS-dataset数据提取"></a>2. GVINS-dataset数据提取</h3><p>为了实现离线训练NN，需要将ros bag转为csv格式数据，写了一个脚本，实现rosbag按topic提取数据并写入csv中</p><h3 id="3-DL扫盲"><a href="#3-DL扫盲" class="headerlink" title="3. DL扫盲"></a>3. DL扫盲</h3><p>参考B站资料对Loss Fun、正则化、CNN、RNN、LSTM、GRU等知识点进行了扫盲</p><h2 id="二、下周怎么安排"><a href="#二、下周怎么安排" class="headerlink" title="二、下周怎么安排"></a>二、下周怎么安排</h2><ol><li>写一个提取GVINS误差的代码<br>原始的GVINS-dataset中只有星历、伪距这些数据，不能进行网络的训练，无法直接在GNSS拒止状态下输出GVINS误差，需要先跑一遍GVINS代码，把各个传感器的误差项提取出来</li><li>用GNSS误差数据对LSTM—NN进行离线训练，并评估效果</li></ol>]]></content>
      
      
      <categories>
          
          <category> NaN </category>
          
          <category> NaN </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch入门笔记</title>
      <link href="/2023/11/25/learn-pytorch/"/>
      <url>/2023/11/25/learn-pytorch/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch入门笔记"><a href="#Pytorch入门笔记" class="headerlink" title="Pytorch入门笔记"></a>Pytorch入门笔记</h1><p><strong>参考资源：bilibili - 我是土堆</strong><br>url : <a href="https://www.bilibili.com/video/BV1hE411t7RN/?spm_id_from=333.999.0.0&vd_source=9761a01d2f08a7425632b3ad97cccf18">https://www.bilibili.com/video/BV1hE411t7RN/?spm_id_from=333.999.0.0&amp;vd_source=9761a01d2f08a7425632b3ad97cccf18</a></p><h1 id="一、-数据加载与预处理"><a href="#一、-数据加载与预处理" class="headerlink" title="一、 数据加载与预处理"></a>一、 数据加载与预处理</h1><h2 id="1-pytorch加载数据"><a href="#1-pytorch加载数据" class="headerlink" title="1. pytorch加载数据"></a>1. pytorch加载数据</h2><p><strong>Dataset的使用</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">from torch.utils.data import Dataset</span><br><span class="line">from PIL import Image</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">class MyData(Dataset):</span><br><span class="line"></span><br><span class="line">    def __init__(self, root_dir, label_dir):</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.label_dir = label_dir</span><br><span class="line">        self.path = os.path.join(self.root_dir, self.label_dir)</span><br><span class="line">        self.img_path = os.listdir(self.path)</span><br><span class="line">        </span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        img_name = self.img_path[index]</span><br><span class="line">        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)</span><br><span class="line">        img = Image.open(img_item_path)</span><br><span class="line">        label = self.label_dir</span><br><span class="line"></span><br><span class="line">        return img, label</span><br><span class="line">    </span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.img_path)</span><br><span class="line">    </span><br><span class="line">root_dir = &#x27;dataset/Type1/train&#x27;</span><br><span class="line">ants_label_dir = &#x27;ants&#x27;</span><br><span class="line">bees_label_dir = &#x27;bees&#x27;</span><br><span class="line"></span><br><span class="line">ants_dataset = MyData(root_dir, ants_label_dir)</span><br><span class="line">bees_dataset = MyData(root_dir, bees_label_dir)</span><br><span class="line"></span><br><span class="line">train_dataset = ants_dataset + bees_dataset</span><br><span class="line"></span><br><span class="line">img, label = train_dataset[0]</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-TensorBoard的使用"><a href="#2-TensorBoard的使用" class="headerlink" title="2. TensorBoard的使用"></a>2. TensorBoard的使用</h2><p>用于训练模型的时候显示图像（LOSS曲线）等</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line">import numpy as np</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(&quot;logs&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img_path = &#x27;dataset/Type1/train/ants/6240329_72c01e663e.jpg&#x27;</span><br><span class="line">img = Image.open(img_path)</span><br><span class="line">img_array = np.array(img)</span><br><span class="line"></span><br><span class="line">writer.add_image(&#x27;test&#x27;, img_array, 1, dataformats=&#x27;HWC&#x27;) # 显示图像</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># for i in range(100):</span><br><span class="line">#     writer.add_scalar(&#x27;y = x&#x27;, 2*i, i) # 显示标量数据</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># writer.add_scalar()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><p>在终端输入：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=logs</span><br></pre></td></tr></table></figure><p>在浏览器中即可看到显示的图像</p><h2 id="3-Transforms的使用"><a href="#3-Transforms的使用" class="headerlink" title="3. Transforms的使用"></a>3. Transforms的使用</h2><p>Transforms主要是对图像进行一些变换</p><p><strong>a. Transforms 应该如何使用</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from PIL import Image</span><br><span class="line">from torchvision import transforms</span><br><span class="line"></span><br><span class="line">img_path = &quot;dataset/Type1/train/ants/6743948_2b8c096dda.jpg&quot;</span><br><span class="line"></span><br><span class="line">img = Image.open(img_path)</span><br><span class="line"></span><br><span class="line">tensor_trans = transforms.ToTensor() # 对象实例化</span><br><span class="line">tensor_img = tensor_trans(img)</span><br><span class="line"></span><br><span class="line">print(tensor_img)</span><br></pre></td></tr></table></figure><p><strong>b. 为什么需要使用tensor的数据类型</strong></p><p>tensor可以简单粗暴的理解为将图片等传统的数据封装为神经网络所需的数据类型</p><p><strong>c. 常见的transforms</strong></p><ol><li><p>Compose<br> compose()中的参数需要是一个列表，且列表中的数据需要时transforms类型，即：<br> compose([tansforms参数1， tansforms参数2])</p><p> 在我理解compose是将多个图像操作合起来了，例如将图像先裁剪再转换为tensor格式<br> 【tansforms参数1】的输出需要时【tansforms参数2】的输入，注意格式需要满足衔接需求</p></li><li><p>ToTensor<br> 将PIL或者opencv的数据格式转换为tensor的格式</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor_trans = transforms.ToTensor() </span><br><span class="line">tensor_img = tensor_trans(img)</span><br></pre></td></tr></table></figure></li><li><p>Normalize<br> 归一化</p> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">trans_norm = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # mean std</span><br><span class="line">img_norm = trans_norm(tensor_img)</span><br></pre></td></tr></table></figure></li><li><p>Resize<br>trans_resize &#x3D; transforms.Resize((128, 128))<br>or<br>trans_resize &#x3D; transforms.Resize((128))<br>img_resize &#x3D; trans_resize(img)</p></li><li><p>RandomCrop<br>用法同Resize</p></li></ol><h2 id="4-torchvision中的Dataset使用"><a href="#4-torchvision中的Dataset使用" class="headerlink" title="4. torchvision中的Dataset使用"></a>4. torchvision中的Dataset使用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">import torchvision</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=&quot;./my_dataset&quot;,</span><br><span class="line">                                         train=True,</span><br><span class="line">                                         download=True,</span><br><span class="line">                                         transform=dataset_transform)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=&quot;./my_dataset&quot;,</span><br><span class="line">                                        train=False,</span><br><span class="line">                                        download=True,</span><br><span class="line">                                        transform=dataset_transform)</span><br><span class="line"></span><br><span class="line"># dataset_transforms = torchvision.transforms.Compose([])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># img.show()</span><br><span class="line">writer = SummaryWriter(&#x27;pic10&#x27;)</span><br><span class="line"></span><br><span class="line">print(test_set[0])</span><br><span class="line"></span><br><span class="line">for i in range(10):</span><br><span class="line">    img, target = test_set[i]</span><br><span class="line">    writer.add_image(&#x27;pic&#x27;, img, i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h2 id="5-DataLoader的使用"><a href="#5-DataLoader的使用" class="headerlink" title="5. DataLoader的使用"></a>5. DataLoader的使用</h2><p>DataLoader参数说明：<br>– dataset：打包好的tensor格式的数据<br>– batch_size： 一轮抓数据的个数（每一轮抓图片的张数）<br>– shuffle： 每个epoch结束后是否打乱所有图片（True为打乱，False为不打乱）<br>– num_workers: 多线程运行数（在windows下运行时此变量若大于1可能会出错）<br>– drop_last：最后一组数据不够一个batch_size数量时，是否丢弃，True为丢弃，False为不丢弃</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import torchvision</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(&quot;./my_dataset&quot;, train=False, transform=dataset_transform, download=True)</span><br><span class="line">test_loader = DataLoader(dataset=test_data, batch_size=128, shuffle=True, num_workers=0, drop_last=False)</span><br><span class="line"></span><br><span class="line">img, target = test_data[0]</span><br><span class="line">print(img.shape)</span><br><span class="line">print(target)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(&#x27;dataloader&#x27;)</span><br><span class="line"></span><br><span class="line">step = 0</span><br><span class="line">for data in test_loader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    # print(imgs.shape)</span><br><span class="line">    # print(targets)</span><br><span class="line">    writer.add_images(&quot;dataloader&quot;, imgs, step)</span><br><span class="line">    step = step + 1</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h1 id="二、神经网络"><a href="#二、神经网络" class="headerlink" title="二、神经网络"></a>二、神经网络</h1><h2 id="6-神经网络基本骨架nn-Module的使用"><a href="#6-神经网络基本骨架nn-Module的使用" class="headerlink" title="6. 神经网络基本骨架nn.Module的使用"></a>6. 神经网络基本骨架nn.Module的使用</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line"></span><br><span class="line">class Damon(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__() # 调用父类的方法</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = input + 1</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">damon = Damon()</span><br><span class="line">x = torch.tensor(1.0)</span><br><span class="line">output = damon(x)</span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><h2 id="7-卷积操作"><a href="#7-卷积操作" class="headerlink" title="7. 卷积操作"></a>7. 卷积操作</h2><ol><li>torch.nn是对torch.nn.function的封装，一般会torch.nn即可</li><li>conv2d()函数操作<br> stride：步进，即每次卷积核移动的距离<br> padding：图片边缘掩膜填充</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line"></span><br><span class="line">input = torch.tensor([[1, 2, 0, 3, 1],</span><br><span class="line">                      [0, 1, 2, 3, 1],</span><br><span class="line">                      [1, 2, 1, 0, 0],</span><br><span class="line">                      [5, 2, 3, 1, 1],</span><br><span class="line">                      [2, 1, 0, 1, 1]])</span><br><span class="line"></span><br><span class="line">kernel = torch.tensor([[1, 2, 1],</span><br><span class="line">                       [0, 1, 0],</span><br><span class="line">                       [2, 1, 0]])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">input = torch.reshape(input, (1, 1, input.shape[0], input.shape[1]))</span><br><span class="line">kernel = torch.reshape(kernel, (1, 1, kernel.shape[0], kernel.shape[1]))</span><br><span class="line"></span><br><span class="line">output = F.conv2d(input, kernel, stride=1, padding=1)</span><br><span class="line"></span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><h2 id="8-卷积层"><a href="#8-卷积层" class="headerlink" title="8. 卷积层"></a>8. 卷积层</h2><p>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride&#x3D;1, padding&#x3D;0, dilation&#x3D;1, groups&#x3D;1, bias&#x3D;True, padding_mode&#x3D;’zeros’, device&#x3D;None, dtype&#x3D;None)</p><p>– in_channels： 输入图像的通道数，一般彩色图像都是3<br>– out_channels： 输出通道数<br>– kernel_size ： 卷积核大小，例如3（即3<em>3的卷积核） （1，2）（即1</em>2的卷积核，不规则卷积核），定义的时候只需要设定卷积核大小，卷积核的值会自动采样得到<br>– stride ： 卷积核步进<br>– padding：边缘填充<br>– padding_mode&#x3D;’zeros’： 以0填充<br>– bias：偏置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Conv2d</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;./my_dataset&quot;,</span><br><span class="line">                                       train=False,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=True)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=64)</span><br><span class="line"></span><br><span class="line">class Damon(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Damon, self).__init__()</span><br><span class="line">        self.conv1 = Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=0)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line">damon = Damon()</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(&#x27;./logs&#x27;)</span><br><span class="line"></span><br><span class="line">step = 0</span><br><span class="line">for data in dataloader:</span><br><span class="line">    step = step + 1</span><br><span class="line">    imgs, targets = data</span><br><span class="line"></span><br><span class="line">    output = damon(imgs)</span><br><span class="line">    # print(output.shape)</span><br><span class="line">    writer.add_images(&#x27;input&#x27;, imgs, step)</span><br><span class="line"></span><br><span class="line">    # output = torch.reshape(output, (-1, 3, 30, 30))</span><br><span class="line">    # output = output.view(-1, 3, 30, 30)</span><br><span class="line">    writer.add_images(&#x27;output&#x27;, output, step)</span><br></pre></td></tr></table></figure><h2 id="9-池化层"><a href="#9-池化层" class="headerlink" title="9. 池化层"></a>9. 池化层</h2><p>最大池化又称下采样<br>最大池化的作用是：保持输入数据的特征，同时减小数据量，网络参数会减少，训练速度会更快<br>所以在很多网络中，大家卷积完之后都会来一次最大池化，然后再来一次非线性激活</p><p>torch.nn.MaxPool2d(kernel_size, stride&#x3D;None, padding&#x3D;0, dilation&#x3D;1, return_indices&#x3D;False, ceil_mode&#x3D;False)<br>参数：<br>– kernel_size (Union[int, Tuple[int, int]]) – the size of the window to take a max over</p><p>– stride (Union[int, Tuple[int, int]]) – the stride of the window. Default value is <strong>kernel_size</strong> （区别卷积层的default是1）</p><p>– padding (Union[int, Tuple[int, int]]) – Implicit negative infinity padding to be added on both sides</p><p>– dilation (Union[int, Tuple[int, int]]) – a parameter that controls the stride of elements in the window （设置空洞卷积）</p><p>– return_indices (bool) – if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later</p><p>– ceil_mode (bool) – when True, will use ceil instead of floor to compute the output shape （default &#x3D; false）<br>ceil和floor的区别看下图</p><p><img src="image.png" alt="Alt text"><br>ceil和floor的具体区别直观展示：<br><img src="image-1.png" alt="Alt text"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import MaxPool2d</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(root=&#x27;./my_dataset&#x27;,</span><br><span class="line">                                       train=False,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=True)</span><br><span class="line">dataload = DataLoader(dataset, batch_size=64)</span><br><span class="line"></span><br><span class="line"># input = torch.tensor([[1, 2, 0, 3, 1],</span><br><span class="line">#               [0, 1, 2, 3, 1],</span><br><span class="line">#               [1, 2, 1, 0, 0],</span><br><span class="line">#               [5, 2, 3, 1, 1],</span><br><span class="line">#               [2, 1, 0, 1, 1]], dtype=torch.float32)</span><br><span class="line"># input = torch.reshape(input, (-1, 1, 5, 5))</span><br><span class="line"></span><br><span class="line">class Damon(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Damon, self).__init__()</span><br><span class="line">        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = self.maxpool1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">damon = Damon();</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(&#x27;logs&#x27;)</span><br><span class="line">step = 0</span><br><span class="line">for data in dataload:</span><br><span class="line">    step = step + 1</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = damon(imgs)</span><br><span class="line">    writer.add_images(&#x27;maxpool&#x27;, output, step)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="10-padding层"><a href="#10-padding层" class="headerlink" title="10. padding层"></a>10. padding层</h2><p>对输入图像周围进行填充<br>一般用不到，因为一般在conv中我们会通过padding参数进行填充</p><p>eg：nn.ZeroPad2d</p><ul><li>Pads the input tensor boundaries with zero.</li></ul><h2 id="11-非线性激活"><a href="#11-非线性激活" class="headerlink" title="11. 非线性激活"></a>11. 非线性激活</h2><p>非线性变换的主要目的就是为了给网络中引入一些非线性特征<br>因为非线性特征越多的话，模型泛化能力越好</p><p>eg:<br><strong>–ReLu:</strong><br>小于0时进行阶段，大于0时原样输出<br><img src="image-2.png" alt="Alt text"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import ReLU</span><br><span class="line"></span><br><span class="line">input = torch.tensor([[1, -0.5],</span><br><span class="line">             [-0.2, 3]])</span><br><span class="line"></span><br><span class="line">class Damon(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Damon, self).__init__()</span><br><span class="line">        self.relu1 = ReLU()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = self.relu1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">damon = Damon()</span><br><span class="line">output = damon(input)</span><br><span class="line"></span><br><span class="line">print(output)</span><br></pre></td></tr></table></figure><p><strong>– sigmoid</strong><br><img src="image-3.png" alt="Alt text"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Sigmoid</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(root=&#x27;./my_dataset&#x27;,</span><br><span class="line">                                       train=False,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=True)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=64)</span><br><span class="line"></span><br><span class="line">class Damon(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Damon, self).__init__()</span><br><span class="line">        self.sigmoid1 = Sigmoid()</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = self.sigmoid1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">damon = Damon()</span><br><span class="line">writer = SummaryWriter(&#x27;./logs&#x27;)</span><br><span class="line">step = 0</span><br><span class="line">for data in dataloader:</span><br><span class="line">    step = step + 1</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = damon(imgs)</span><br><span class="line">    writer.add_images(&#x27;sigmoid&#x27;, output, step)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h2 id="12-线性层及其它层"><a href="#12-线性层及其它层" class="headerlink" title="12. 线性层及其它层"></a>12. 线性层及其它层</h2><ol><li>正则化层<br>采用正则化层可以加快网络的训练速度<br>用的比较少</li><li>Recurrent Layers<br>RNN &#x2F;LSTM etc<br>属于特定的网络结构</li><li>Transformer Layer</li><li>线性层<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Linear</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(&quot;./my_dataset&quot;,</span><br><span class="line">                                       train=False,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=True)</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=64)</span><br><span class="line"></span><br><span class="line">class Damon(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Damon, self).__init__()</span><br><span class="line">        self.linear1 = Linear(196608,10)</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = self.linear1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">t = Damon()</span><br><span class="line">for data in dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    imgs = torch.flatten(imgs)</span><br><span class="line">    output = t(imgs)</span><br><span class="line">    print(output.shape)</span><br></pre></td></tr></table></figure></li><li>Dropout Layer<br>为了防止模型过拟合</li><li>Flatten 展平<br>from torch.nn import Flatten<br>self.flatten &#x3D; Flatten()</li></ol><h2 id="13-NN-搭建实战和Sequential的使用"><a href="#13-NN-搭建实战和Sequential的使用" class="headerlink" title="13. NN 搭建实战和Sequential的使用"></a>13. NN 搭建实战和Sequential的使用</h2><p><strong>a. Sequential的使用</strong><br>Sequential类似于compose,是将多个操作（层）合起来的一个工具</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">model = nn.Sequential(</span><br><span class="line">          nn.Conv2d(1,20,5),</span><br><span class="line">          nn.ReLU(),</span><br><span class="line">          nn.Conv2d(20,64,5),</span><br><span class="line">          nn.ReLU()</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = nn.Sequential(OrderedDict([</span><br><span class="line">          (&#x27;conv1&#x27;, nn.Conv2d(1,20,5)),</span><br><span class="line">          (&#x27;relu1&#x27;, nn.ReLU()),</span><br><span class="line">          (&#x27;conv2&#x27;, nn.Conv2d(20,64,5)),</span><br><span class="line">          (&#x27;relu2&#x27;, nn.ReLU())</span><br><span class="line">        ]))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><strong>b. CIFAR10 Network_model</strong><br><img src="image-4.png" alt="Alt text"></p><p>Tips：使用TensorBoard中的add_graph可以将网络展开成如下形状，便于直观检查网络的问题</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">writer = SummaryWriter(&#x27;./logs&#x27;)</span><br><span class="line">writer.add_graph(damon, input)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><p><img src="image-5.png" alt="Alt text"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch import nn</span><br><span class="line">from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line">from torch.utils.tensorboard import SummaryWriter</span><br><span class="line"></span><br><span class="line">class Damon(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super(Damon, self).__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(3, 32, 5, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Conv2d(32, 32, 5, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Conv2d(32, 64, 5, padding=2),</span><br><span class="line">            MaxPool2d(2),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(1024, 64),</span><br><span class="line">            Linear(64, 10)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = self.model1(input)</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">damon = Damon()</span><br><span class="line"></span><br><span class="line">input = torch.ones((64, 3, 32, 32))</span><br><span class="line">output = damon(input)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(&#x27;./logs&#x27;)</span><br><span class="line">writer.add_graph(damon, input)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure><h1 id="三、-pytorch应用"><a href="#三、-pytorch应用" class="headerlink" title="三、 pytorch应用"></a>三、 pytorch应用</h1><h2 id="14-损失函数与反向传播"><a href="#14-损失函数与反向传播" class="headerlink" title="14. 损失函数与反向传播"></a>14. 损失函数与反向传播</h2><p>a. Loss Fun的作用<br>    1.计算实际输出和实际目标之间的差距<br>    2.为参数更新提供依据（反向传播）<br>    实际上神经网络的参数就是卷积核的参数，参数更新就是根据loss计算参数的梯度，以便进行梯度下降，达到Loss下降的目的<br>b. 常用的LOSS函数<br>    L1Loss<br>    MSELoss<br>    CrossEntropyLoss 交叉熵损失 分类中常用<br><img src="image-6.png" alt="Alt text"><br>c. 反向传播代码<br>反向传播会求出每一个参数的梯度</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for data in dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = damon(imgs)</span><br><span class="line">    print(output)</span><br><span class="line">    print(&#x27;target:&#x27;, targets)</span><br><span class="line">    loss = celoss(output, targets)</span><br><span class="line">    loss.backward()</span><br><span class="line">    print(&#x27;loss:&#x27;, loss)</span><br><span class="line">    exit()</span><br></pre></td></tr></table></figure><h2 id="15-优化器"><a href="#15-优化器" class="headerlink" title="15. 优化器"></a>15. 优化器</h2><p><strong>a. 优化器的使用套路</strong></p><p>定义一个优化器，设置模型参数和学习率等参数<br><code>optim = torch.optim.SGD(damon.parameters(), lr=0.01)</code><br>↓<br>在每个batch_size中,先清零梯度，因为上一次的梯度对于本次的训练是没用的<br><code>optim.zero_grad()</code><br>↓<br>loss反向传播<br><code>loss.backward()</code><br>↓<br>执行优化,即：模型参数调优<br><code>optim.step()</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">damon = Damon() # instantiation</span><br><span class="line">celoss = nn.CrossEntropyLoss() # Loss definition</span><br><span class="line">optim = torch.optim.SGD(damon.parameters(), lr=0.01)</span><br><span class="line"></span><br><span class="line">for epoch in range(20):</span><br><span class="line">    run_loss = 0.0</span><br><span class="line">    for data in dataloader:</span><br><span class="line">        optim.zero_grad()</span><br><span class="line"></span><br><span class="line">        imgs, targets = data</span><br><span class="line">        output = damon(imgs)</span><br><span class="line"></span><br><span class="line">        loss = celoss(output, targets)</span><br><span class="line">        loss.backward()</span><br><span class="line"></span><br><span class="line">        optim.step()</span><br><span class="line">        run_loss = run_loss + loss</span><br><span class="line">    print(run_loss)</span><br></pre></td></tr></table></figure><p><strong>b. 学习率</strong></p><p>学习速率太大，模型训练起来就很不稳定<br>学习速率太小，模型训练会很慢</p><p>一般先用大的学习速率，再用小的学习速率</p><h2 id="16-现有模型的加载使用与修改"><a href="#16-现有模型的加载使用与修改" class="headerlink" title="16. 现有模型的加载使用与修改"></a>16. 现有模型的加载使用与修改</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vgg16_raw = torchvision.models.vgg16() # 加载VGG16</span><br><span class="line"></span><br><span class="line">vgg16_raw.add_module(&#x27;my_linear&#x27;, nn.Linear(1000, 10)) # 在vgg16后面加线性层</span><br><span class="line">vgg16_raw.classifier.add_module(&quot;my_linear2&quot;, nn.Linear(100, 100)) # 在vgg16的classifier后面加线性层</span><br><span class="line">vgg16_raw.classifier[6] = nn.Linear(4096, 10) # 修改vgg16的classifier的6号网络层为Linear(4096, 10)</span><br></pre></td></tr></table></figure><h2 id="17-网络模型的保存与读取"><a href="#17-网络模型的保存与读取" class="headerlink" title="17. 网络模型的保存与读取"></a>17. 网络模型的保存与读取</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># raw method</span><br><span class="line">vgg16 = torchvision.models.vgg16()</span><br><span class="line"></span><br><span class="line">**# save method1:**</span><br><span class="line">torch.save(vgg16, &quot;vgg16_method1.pth&quot;)</span><br><span class="line"></span><br><span class="line"># load method1:</span><br><span class="line">model1 = torch.load(&quot;vgg16_method1.pth&quot;)</span><br><span class="line"># -------------------------</span><br><span class="line"></span><br><span class="line">**# save method2:** （官方推荐的方式）</span><br><span class="line">torch.save(vgg16.state_dict(), &#x27;vgg16_method2.pth&#x27;)</span><br><span class="line"></span><br><span class="line"># load method2:</span><br><span class="line">model2 = torch.load(&quot;vgg16_method2.pth&quot;) # only load model parameter, not contains the construction of the model</span><br><span class="line">vgg16.load_state_dict(torch.load(&quot;vgg16_method2.pth&quot;))</span><br></pre></td></tr></table></figure><h2 id="18-完成的模型训练套路（以CIFAR10为例）"><a href="#18-完成的模型训练套路（以CIFAR10为例）" class="headerlink" title="18. 完成的模型训练套路（以CIFAR10为例）"></a>18. 完成的模型训练套路（以CIFAR10为例）</h2><p>a. 使用正确率评估模型（分类问题中特有的评价指标）<br>意思就是：测试集中分类正确的图片占比多少？</p><p>完整的代码在github的project子文件夹下 train.py, 模型在model.py里</p><p>b. 训练模型的一些细节</p><ol><li>有的人在训练前会加damon.train()&#x2F;在验证前加damon.eval()等字样，这个不是必须的，这个代码只对某些层有效（例如Dropout、BatchNorm等），但是如果自己的网络里有这些特殊的层，就必须在训练&#x2F;测试前调用这些代码</li></ol><h2 id="19-使用GPU进行训练"><a href="#19-使用GPU进行训练" class="headerlink" title="19. 使用GPU进行训练"></a>19. 使用GPU进行训练</h2><p>a. 第一种方法<br>找到【模型】、【数据（输入+标注）】、【损失函数】，在这三个后面加一句.cuda()<br>eg:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">damon = Damon()</span><br><span class="line">damon = damon.cuda()</span><br></pre></td></tr></table></figure><p>b. 第二种方法<br>使用.todevice()方法</p><p>device &#x3D; torch.device(‘cpu’) # 使用CPU<br>         torch.device(‘cuda’) # 使用GPU<br>         torch.device(‘cuda:0’) # 有多张显卡时，使用第一张GPU<br>         torch.device(‘cuda:1’) # 有多张显卡时，使用第2张GPU</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(&#x27;cpu&#x27;)</span><br><span class="line"></span><br><span class="line">damon = Damon()</span><br><span class="line">damon = damon.to(device)</span><br></pre></td></tr></table></figure><p>更常见的一种方式：<br><code>device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</code></p><p>c. 如果自己没有GPU可以去谷歌的colab蹭</p><h2 id="18-完成的模型测试套路"><a href="#18-完成的模型测试套路" class="headerlink" title="18. 完成的模型测试套路"></a>18. 完成的模型测试套路</h2><p>核心：利用已经训练好的模型吗，给他提供输入，进行模型推理</p><p>步骤：找测试数据（eg：图片）-&gt; reshape到模型接受的大小 -&gt; 输入模型推理</p><p>Attention: 如果模型实在GPU上训练的，那么使用CPU推理，在加载时需要制定map_location，即：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = torch.load(&#x27;model.pth&#x27;, map_location=torch.device(&#x27;cpu&#x27;))</span><br></pre></td></tr></table></figure><h3 id="19-看看开源项目"><a href="#19-看看开源项目" class="headerlink" title="19. 看看开源项目"></a>19. 看看开源项目</h3><p>1. </p>]]></content>
      
      
      <categories>
          
          <category> NaN </category>
          
          <category> NaN </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>周报-001-19Nov2023</title>
      <link href="/2023/11/18/WeeklyReport-001-19Nov2023/"/>
      <url>/2023/11/18/WeeklyReport-001-19Nov2023/</url>
      
        <content type="html"><![CDATA[<h1 id="工作周报"><a href="#工作周报" class="headerlink" title=" 工作周报 "></a><p style="text-align: center;"> 工作周报 </p></h1><p style="text-align: center;"> <b>时间: </b> 2023-11-13 ~ 2023-11-18 </p><br><h2 id="一、本周做了什么"><a href="#一、本周做了什么" class="headerlink" title="一、本周做了什么"></a>一、本周做了什么</h2><p>本周主要同步推进paper和硬件小车这两件事，主要有：</p><ol><li>Paper Reading：在 <strong>GNSS-Visual-Inertial-odometry(GVIO)</strong> 领域阅读文献多篇，其中精读3篇，并完成Reading Note（纸质），</li><li>Paper Writing: 完成了<strong>论文的（通用）部分</strong>，主要包含：<strong>坐标系的转换描述</strong>、<strong>因子图原理</strong>、<strong>Introduction部分的骨架</strong>等。</li><li>Code  Reading: 捋完了<strong>GVINS</strong>的框架，将其作为Code-Baseline在这上面修改。</li><li>学习LSTM，并基于LSTM完成了一个股票数据的预测，算作入门。</li><li>调校小车：摸清了 <strong>传感器数据采集→STM32数据收集和转发→PC机（ubuntu+ROS）</strong>的全流程；将计算任务转移到<strong>个人PC</strong>上运行；在线运行ORB-SLAM2纯视觉建图<strong>效果一般但不卡</strong>；将小车部分的启动步骤、参数细节整理成了文档。</li><li>制作做CAC会议海报，来重庆开会。</li></ol><h2 id="二、有什么收获-启发-问题"><a href="#二、有什么收获-启发-问题" class="headerlink" title="二、有什么收获&#x2F;启发&#x2F;问题"></a>二、有什么收获&#x2F;启发&#x2F;问题</h2><h3 id="2-1-Paper-Reading-GVIO"><a href="#2-1-Paper-Reading-GVIO" class="headerlink" title="2.1 Paper Reading - GVIO"></a>2.1 Paper Reading - GVIO</h3><p>  详情在纸质版笔记上，供论文的Related Work部分使用。</p><h3 id="2-2-Code-Reading-Writting-GVINS"><a href="#2-2-Code-Reading-Writting-GVINS" class="headerlink" title="2.2 Code  Reading &amp; Writting - GVINS"></a>2.2 Code  Reading &amp; Writting - GVINS</h3><ol><li>我详细阅读并注释了GVINS的代码，并已经push到我的github，链接：<a href="https://github.com/wxtcon/gvins_comments_by_damon">https://github.com/wxtcon/gvins_comments_by_damon</a></li><li>编写选星这部分算法代码，基于GVINS-Dataset测试，这会还没写完，预计下周写完并测试</li></ol><h3 id="2-3-调校小车"><a href="#2-3-调校小车" class="headerlink" title="2.3 调校小车"></a>2.3 调校小车</h3><p><strong>工作细节</strong></p><ol><li><p>尚未定位为什么在Jetson TX2上ORB-SLAM3非常卡（<strong>一核有难，三核围观</strong>）的原因，这个问题定位起来有点麻烦（<strong>暂缓</strong>）</p></li><li><p>鉴于问题1.难定位，我将工控机的所有任务转移到<strong>个人PC</strong>上进行，目前<strong>全流程已经打通</strong>（包括环境配置、代码编译测试、运行测试），现阶段小车长这样<br><img src="IMG_20231115_150317.jpg" alt="Alt text"><br><img src="IMG_20231115_150312.jpg" alt="Alt text"></p></li><li><p>使用<strong>camera-calibration</strong>工具完成了摄像头的标定，标定工具界面如下:<br><img src="cailb.bmp" alt="Alt text"></p></li><li><p>在PC上编译并运行ORB-SLAM2，在<strong>会议室</strong>进行纯视觉建图测试，<br><img src="1.bmp" alt="Alt text"><br>体素地图效果如下：<br>  <img src="2.bmp" alt="Alt text"><br>  可以发现下面这块地图发生了较大的偏移，这是因为这块地方都是墙壁，特征点太少了，发生了退化</p></li><li><p>将上述工作整理成了一个简单的文档备查<br>文档链接：<a href="http://www.damonai.cn/2023/11/15/Car-Info/">www.damonai.cn/2023/11/15/Car-Info/</a></p></li></ol><h3 id="2-4-LSTM学习"><a href="#2-4-LSTM学习" class="headerlink" title="2.4 LSTM学习"></a>2.4 LSTM学习</h3><p>学习LSTM原理，在服务器上跑了一个预测股票的demo，<br><img src="image.png" alt="Alt text"><br>之前没怎么搞过深度学习，正在补基础知识</p><h2 id="三、下阶段怎么安排"><a href="#三、下阶段怎么安排" class="headerlink" title="三、下阶段怎么安排"></a>三、下阶段怎么安排</h2><ol><li>计划用两天左右时间完成深度学习基础+RNN+LSTM扫盲</li><li>完成卫星选星算法代码的编写和效果测试（基于GVINS-Dataset）。</li><li>完成小车硬件升级：小车加高，先加一层50cm（200&#x2F;层，已买），后续视情况判断是否再加一层(凑1m)<br><img src="Screenshot_2023-11-15-23-25-47-030_com.taobao.tao.jpg" alt="Alt text"></li></ol><p><br><br></p>]]></content>
      
      
      <categories>
          
          <category> NaN </category>
          
          <category> NaN </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Car-Info</title>
      <link href="/2023/11/15/Car-Info/"/>
      <url>/2023/11/15/Car-Info/</url>
      
        <content type="html"><![CDATA[<h1 id="小车信息"><a href="#小车信息" class="headerlink" title=" 小车信息 "></a><p style="text-align: center;"> 小车信息 </p></h1><h2 id="一、常用配置命令"><a href="#一、常用配置命令" class="headerlink" title="一、常用配置命令"></a>一、常用配置命令</h2><ol><li><p>在工作空间下运行，安装ROS功能包全部依赖（镜像中已配置rosdep）：<br>rosdep install –from-paths src –ignore-src -r -y</p></li><li><p>指定功能包编译：<br>catkin_make -DCATKIN_WHITELIST_PACKAGES&#x3D;”功能包名”<br>解除指定功能包编译：<br>catkin_make -DCATKIN_WHITELIST_PACKAGES&#x3D;””</p></li><li><p>打开摄像头并使用rqt工具查看图像话题：<br>roslaunch turn_on_wheeltec_robot wheeltec_camera.launch<br>rqt_image_view</p></li><li><p>生成TF树pdf<br>rosrun tf view_frames</p></li><li><p>查看TF树<br>rosrun rqt_tf_tree rqt_tf_tree</p></li><li><p>nfs挂载:<br>sudo mount -t nfs 192.168.0.100:&#x2F;home&#x2F;wheeltec&#x2F;wheeltec_robot &#x2F;mnt<br>nfs解除挂载:<br>sudo umount -t nfs 192.168.0.100:&#x2F;home&#x2F;wheeltec&#x2F;wheeltec_robot &#x2F;mnt</p></li></ol><h2 id="二、常用功能命令"><a href="#二、常用功能命令" class="headerlink" title="二、常用功能命令"></a>二、常用功能命令</h2><p><strong>1.开启初始化节点</strong><br>（仅在单独开启键盘控制时需要开启 运行功能时已包括初始化节点 不需要重复开启）<br>roslaunch turn_on_wheeltec_robot turn_on_wheeltec_robot.launch<br>&#x2F;&#x2F;开启键盘控制节点<br>roslaunch wheeltec_robot_rc keyboard_teleop.launch</p><p><strong>2.ORB-SLAM2建图</strong><br>&#x2F;&#x2F;开启ORB节点<br>roslaunch turn_on_wheeltec_robot orb_slam.launch<br>&#x2F;&#x2F;开启rviz可视化工具<br>rviz -d robot_ws&#x2F;src&#x2F;orb_slam2_ros-master&#x2F;ros&#x2F;launch&#x2F;orb_slam.rviz<br>（rviz配置文件路径：orb_slam2_ros-master&#x2F;ros&#x2F;launch&#x2F;orb_slam.rviz）<br>&#x2F;&#x2F; 手动保存地图(在地图要保存路径下运行)：<br>rosrun map_server map_saver -f </p><h2 id="三、Astra-Pro相机内参数"><a href="#三、Astra-Pro相机内参数" class="headerlink" title="三、Astra Pro相机内参数"></a>三、Astra Pro相机内参数</h2><p><strong>[标定时间]</strong><br>10 Nov 2023</p><p><strong>[image]</strong><br>width x height &#x3D;  640 x 480</p><p><strong>[narrow_stereo]</strong><br><strong>camera matrix</strong><br>542.266049 0.000000 335.743717<br>0.000000 541.768934 234.053530<br>0.000000 0.000000 1.000000</p><p><strong>distortion</strong><br>0.055829 -0.287435 0.004553 0.008338 0.000000</p><p><strong>rectification</strong><br>1.000000 0.000000 0.000000<br>0.000000 1.000000 0.000000<br>0.000000 0.000000 1.000000</p><p><strong>projection</strong><br>529.754089 0.000000 342.777112 0.000000<br>0.000000 541.307739 234.928954 0.000000<br>0.000000 0.000000 1.000000 0.000000</p>]]></content>
      
      
      <categories>
          
          <category> Car-Info </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Car-Info </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>这是第一篇本站的第一篇文章</title>
      <link href="/2023/11/04/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/"/>
      <url>/2023/11/04/%E7%AC%AC%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="创站帖"><a href="#创站帖" class="headerlink" title="创站帖"></a>创站帖</h1><p>本站建立于<strong>2023-11-4</strong><br>由<strong>Damon</strong>创建，作为私人博客</p><p>本站基于<strong>Hexo</strong>架构<br>使用<strong>butterfly</strong>主题<br>基于<strong>github</strong>、<strong>vercel</strong>实现网页代码托管<br>使用<strong>阿里云</strong>实现国内访问的映射</p><p>主站：wxtcon.github.io<br>vercel映射：wxtcon.vercel.app<br>阿里云映射：<a href="http://www.damonai.cn/">www.damonai.cn</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
